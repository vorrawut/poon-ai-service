@startuml System Overview
!theme aws-orange
title Poon AI Service - System Overview

package "Frontend (React)" {
  class PhotoOCRInput
  class VoiceInput
  class ChatTextInput
  class ManualFormInput
  class FileUploadInput
  class QuickTemplateInput
}

package "AI Microservice (FastAPI)" {
  class "FastAPI App" as App
  class "OCR Service" as OCR
  class "NLP Service" as NLP
  class "Enhanced Llama Service" as Llama
  class "AI Service (OpenAI)" as OpenAI
  class "Cache Service" as Cache
}

package "External Services" {
  class "Ollama (Local)" as OllamaExt
  class "OpenAI API" as OpenAIAPI
  class "Redis Cache" as RedisExt
  class "Tesseract OCR" as TesseractExt
}

package "Main Backend (NestJS)" {
  class "Spending Controller" as Controller
  class "Database (PostgreSQL)" as DB
}

' Frontend to AI Service connections
PhotoOCRInput --> App : POST /process/receipt
VoiceInput --> App : POST /process/text
ChatTextInput --> App : POST /llama/parse
ManualFormInput --> Controller : Direct save
FileUploadInput --> App : POST /process/batch
QuickTemplateInput --> Controller : Direct save

' AI Service internal connections
App --> OCR : Image processing
App --> NLP : Text parsing
App --> Llama : AI enhancement (primary)
App --> OpenAI : AI fallback
App --> Cache : Result caching

' External service connections
OCR --> TesseractExt : Local OCR
Llama --> OllamaExt : Local Llama4
OpenAI --> OpenAIAPI : Cloud API
Cache --> RedisExt : Cache storage

' AI Service to Main Backend
App --> Controller : Processed spending entries

' Main Backend to Database
Controller --> DB : Store spending data

note right of Llama : Enhanced Llama4\n(FREE, Local, Private)
note right of OpenAI : Fallback AI\n(Paid, Cloud)
note right of OllamaExt : Llama 3.2 3B Model\nRunning Locally

@enduml
